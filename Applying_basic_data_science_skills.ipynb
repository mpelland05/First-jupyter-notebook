{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An exercise in basic data science skills\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook was developped in order to practice skills I have learned following the first part of the DataQuest data science tutorial. But, it can be of use to anyone who is interested in learning the basics of python since it uses the jupyter book format which is ideal for learning or trying coding (or so people say). \n",
    "\n",
    "The fictional goal of the present exercise is to help a company that builds Android and iOS mobile apps. Since most of their profits come from advertisements on said applications (they only produce free apps), the goal is to find what types of free apps are most likely to be downloaded. Note: the market is english speaking users. \n",
    "\n",
    "The exercise consists of 4 analysis steps:\n",
    " 1. Downloading the file and separating the headers.\n",
    " 2. Visually explore the data.\n",
    " 3. Cleaning the data.\n",
    " 4. Analysis proper in order to provide insights to the fictional company. \n",
    "\n",
    "\n",
    "\n",
    "This exercise uses the following two datasets:\n",
    "https://www.kaggle.com/lava18/google-play-store-apps/home\n",
    "https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home\n",
    "\n",
    "    Note: I have inserted notes such as this one throught the comments. Most of them simply state which lines of codes MUST be run in order for the whole code to function. I also added some notes concerning ways to improve the code. The reason these improvements were not added was for the results of this notebook to be comparable to those of the tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "**The first step is to open the files and separating them from the headers (name of the columns)**\n",
    ". Although the separation of the header from the rest of the file is not mandatory, it will make reading the rest of the information easier. \n",
    "\n",
    "     Note: running the cell below is MANDATORY for the rest of the code to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the google data set\n",
    "from csv import reader\n",
    "opfil = open('googleplaystore.csv', encoding='utf8')\n",
    "tempgoogfil = list(reader(opfil))\n",
    "\n",
    "hdrgoog = tempgoogfil[0]           #header\n",
    "filgoog = tempgoogfil[1:]          #body\n",
    "\n",
    "#Opening the apple data set\n",
    "opfil = open('AppleStore.csv', encoding='utf8')\n",
    "tempappfil = list(reader(opfil))\n",
    "\n",
    "hdrapp = tempappfil[0]           #header\n",
    "filapp = tempappfil[1:]          #body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "**The second step is to explore the data and get an idea of what it contains**\n",
    " \n",
    " In the second step we specify a function that will be used to show the data (the function was kindly provided by dataquest).\n",
    "\n",
    "    Note: running the cell below is MANDATORY for the rest of the code to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data sets can be explored. \n",
    "\n",
    "    Note: running the cell below is FACULTATIVE as it is simply meant to explore the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hdrgoog)\n",
    "explore(filgoog,0,1)\n",
    "\n",
    "print('\\n') #creates new line to space information\n",
    "\n",
    "print(hdrapp)\n",
    "explore(filapp,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A short legend for each of the datasets is now in order.**\n",
    "\n",
    "The legends were taken from the website where the apps are downloaded\n",
    "\n",
    "**Google dataset**\n",
    "\n",
    "    App............... Name\n",
    "    Category.......... Type of app\n",
    "    Rating............ Average rating of the app\n",
    "    Reviews........... # of revies\n",
    "    Size.............. size of app\n",
    "    Installs.......... Number of times the app was downloaded\n",
    "    Type.............. Paid or free\n",
    "    Price.............\n",
    "    Content Rating.... Age group it is allowed for\n",
    "    Genres............ Tool, entertainement, etc\n",
    "    Last updated......\n",
    "    Current version...\n",
    "    Android version...\n",
    "  \n",
    "**Apple dataset**\n",
    "\n",
    "    id................ Apple id\n",
    "    track_name........ App name\n",
    "    size.............. in bytes\n",
    "    currenty        \n",
    "    price           \n",
    "    rating_count_tot.. number or ratings\n",
    "    rating_cout_ver... number of ratings for current version\n",
    "    user_rating....... average rating\n",
    "    user_rating_ver... average rating of current version\n",
    "    ver............... latest version\n",
    "    cont_rating....... age group allowed for\n",
    "    prime_genre....... game, weather, etc\n",
    "    sup_devices.num... number of downloads\n",
    "    ipadSc_urls.num... Number of screenshot for the display\n",
    "    lang.num.......... number of supported languages\n",
    "    vpp_lic........... vpp device based licensing enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 \n",
    "**This step involves cleaning the data (removing errors and unwanted data).**\n",
    "\n",
    "### 3.1 Badly formated data\n",
    "Interestingly, a quick visit on the discussion forum for the data shows that there is an error in one of the data entries. Something about the number of columns not being right. To verify whether it has been corrected and whether other errors existed, I wrote the following function. It searches through every row of the data to make sure that they possess the right number of columns. \n",
    "\n",
    "    Note: running the next 2 cells below is MANDATORY for the rest of the code to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_wrong_col(data,ncol):\n",
    "    count = 0\n",
    "    for rr in data:\n",
    "        if len(rr) != ncol:\n",
    "            print(count)\n",
    "            print(rr)\n",
    "            print('\\n')            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Android')\n",
    "detect_wrong_col(filgoog,len(hdrgoog))\n",
    "print('Apple')\n",
    "detect_wrong_col(filapp,len(hdrapp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!** We can see after running the function that there is inndeed still an error in the google data set. That is, there is a column missing. One way to correct this problem is to delete the entry.  \n",
    "\n",
    "    Note: running the cell below is MANDATORY for the rest of the code to work. But it must be ran only once. It should also be specified that a more ideal step would have been to create a new variable that contained the cleaned up data rather than deleting it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(filgoog[10472]) #Running this line removes the duplicate elements (beware running it more than once, for it will remove good data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Duplicate data\n",
    "Another issue reported on the discussion forums for the data set was that there were duplicate elements. That is, some apps were present more than once. The reason why applications are reported more than once is unknown. To find out, I wrote the following function which will go through the data and identify which apps have duplicate entries and which don't. It also gives an output that can be used to visualize how duplicate entries differ between each other in order to better understand the source of duplicates. \n",
    "\n",
    "    Note: running the following two cells is FACULTATIVE for the rest of the code. Their main use is to inform the user as to the nature of the data. Additionally, the function was improved from that suggested by the turotial The current one has more outputs that could allow a more in depth search of the duplicate entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dupl(data,hdr,nam_col_idx):\n",
    "    #this script will search for duplicate data\n",
    "    nci = nam_col_idx\n",
    "    count = 0\n",
    "    ulist = [] \n",
    "    tempdlist = []\n",
    "\n",
    "    \n",
    "    #first loop to obtain list of the names\n",
    "    for rr in data:\n",
    "        nam = rr[nci]\n",
    "        if nam in ulist:\n",
    "            tempdlist.append(nam)\n",
    "        else:\n",
    "            ulist.append(nam)\n",
    "         \n",
    "    dlist = set(tempdlist) #list ofunique apps without duplicates\n",
    "    \n",
    "    #second loop to compare data for each duplicate app\n",
    "    ncol = len(data[1])\n",
    "    idxdif = []                       #col which show differences across duplicates  \n",
    "    detailed_output = []\n",
    "    for nn in dlist:\n",
    "        first = []                    #used to check whether this is the first entry of an app that later has duplicates\n",
    "        count = 0\n",
    "        for rr in data:\n",
    "            if rr[nci] == nn:         #find instance of the same app\n",
    "                if first:             #check whether it is the first time that this app is encountered\n",
    "                    for co in range(0,ncol-1):    #loops through each colum and compareds them with first instance of app to see where they differ\n",
    "                        if first[co] != rr[co]:\n",
    "                            detailed_output.append([count,hdr[co],first[co],rr[co]])\n",
    "                            \n",
    "                            idxdif.append(co)\n",
    "                else:\n",
    "                    first = rr\n",
    "                    \n",
    "            count += 1\n",
    "            \n",
    "            \n",
    "            \n",
    "    return [idxdif,ulist,dlist,detailed_output]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then when applied to files we get the following results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 9, 10, 11}\n",
      "[5294, 'Reviews', '1343866', '1343106']\n",
      "[2489, 'Reviews', '53743', '53747']\n",
      "[3943, 'Reviews', '78158306', '78128208']\n",
      "[3215, 'Reviews', '359403', '359560']\n",
      "[7937, 'Reviews', '10979062', '10981850']\n",
      "[293, 'Reviews', '1002861', '1002859']\n",
      "[8747, 'Reviews', '21314', '21381']\n",
      "[4068, 'Reviews', '2788923', '2788460']\n",
      "[1735, 'Reviews', '5234162', '5234825']\n",
      "[1757, 'Reviews', '5234162', '5234810']\n",
      "[1891, 'Reviews', '5234162', '5235294']\n",
      "[1921, 'Reviews', '5234162', '5235294']\n",
      "[4227, 'Reviews', '5234162', '5231553']\n",
      "[1855, 'Reviews', '214777', '214819']\n",
      "[5415, 'Reviews', '666521', '666246']\n",
      "[2225, 'Reviews', '1574197', '1574204']\n",
      "[9680, 'Reviews', '1574197', '1574546']\n",
      "[3976, 'Reviews', '815893', '815280']\n",
      "[4989, 'Reviews', '85858', '85782']\n",
      "[8450, 'Reviews', '552441', '552635']\n",
      "\n",
      "\n",
      "\n",
      "{1, 2, 3, 4, 5, 6, 7, 9, 10, 11}\n",
      "[5603, '', '4000', '7579']\n",
      "[5603, 'id', '952877179', '1089824278']\n",
      "[5603, 'size_bytes', '169523200', '240964608']\n",
      "[5603, 'rating_count_tot', '107', '67']\n",
      "[5603, 'rating_count_ver', '102', '44']\n",
      "[5603, 'user_rating_ver', '3.5', '4']\n",
      "[5603, 'ver', '2.0.0', '0.81']\n",
      "[5603, 'sup_devices.num', '37', '38']\n",
      "[5603, 'ipadSc_urls.num', '5', '0']\n",
      "[7128, '', '10751', '10885']\n",
      "[7128, 'id', '1173990889', '1178454060']\n",
      "[7128, 'size_bytes', '109705216', '59572224']\n",
      "[7128, 'rating_count_tot', '668', '105']\n",
      "[7128, 'rating_count_ver', '87', '58']\n",
      "[7128, 'user_rating', '3', '4']\n",
      "[7128, 'user_rating_ver', '3', '4.5']\n",
      "[7128, 'ver', '1.4', '1.0.1']\n",
      "[7128, 'cont_rating', '9+', '4+']\n",
      "[7128, 'sup_devices.num', '37', '38']\n",
      "[7128, 'ipadSc_urls.num', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "idxg,uniquesg,duplicatesg,det_outg = find_dupl(filgoog,hdrgoog,0)\n",
    "print(set(idxg))\n",
    "#explore(det_outg,0,20)\n",
    "for ii in range(0,20):\n",
    "    print(det_outg[ii])\n",
    "    \n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print(set(idxg))\n",
    "idxa,uniquesa,duplicatesa,det_outa = find_dupl(filapp,hdrapp,2)\n",
    "#explore(det_outa,0,20)\n",
    "for ii in range(0,20):\n",
    "    print(det_outa[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Notice that not all outputs of the functions were used. Originally, the different outputs where meant to explore different elements of the data. However, it was particularly obvious from the results displayed above that differences between duplicates were not limited to a specific column but were found across columns. However, the android datasets clearly shows that most differences are found for the number of reviews. This suggests that data were acquired a different times with some having been reviewed by more users. \n",
    "\n",
    "    Note: no duplicates were removed from the Apple Store dataset to keep my results coherent with theirs. Obviously, this should not be avoided in an analysis for a real company. \n",
    "    \n",
    "\n",
    "Thus, when removing the duplicate data, we should aim to keep the most recent entry for each app. This should be the one that contains the highest number of reviews. We will do so using a two step procedure. \n",
    "  - In the first step, we link every unique app to the highest number of review reported for it. To do this, we create a dictionary.\n",
    "  - In the second step, we use the dictionary to clean up the data by selecting only rows where the app's number of review is the highest.\n",
    "\n",
    "Both steps are implemented by the function I wrote below. \n",
    "\n",
    "    Note: running the following two cells is MANDATORY for the rest of the code to funciton properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data,col_nam,col_decision,decision='Highest'):\n",
    "    #This function is meant to go through data and create a new dataset where duplicate entries are deleted and only\n",
    "    #the one meeting a specific criteria is kept. The column for the criteria must be specified as well as the criteria.\n",
    "    #However, right now, only 'highest' is implemented\n",
    "    \n",
    "    coln = col_nam\n",
    "    cold = col_decision\n",
    "    \n",
    "    #creating dictionary\n",
    "    maxnrat = {}\n",
    "    for rr in data:\n",
    "        tnam = rr[coln]\n",
    "        tcond = float(rr[cold])\n",
    "        if rr[coln] in maxnrat:\n",
    "            if (decision == 'Highest') and (tnam in maxnrat) and (tcond > maxnrat[tnam]): #use criterion here, only one implemented for now\n",
    "                maxnrat[tnam] = tcond\n",
    "        else:\n",
    "            maxnrat[tnam] = tcond\n",
    "    \n",
    "    cdata = [] #cleaned data\n",
    "    adlist = []\n",
    "    for rr in data:\n",
    "        tnam = rr[coln]\n",
    "        tcond = float(rr[cold])\n",
    "        if (tnam not in adlist) and (tcond == maxnrat[tnam]):\n",
    "            adlist.append(rr[coln])\n",
    "            cdata.append(rr)\n",
    "            \n",
    "    return cdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfilgoog = clean_data(filgoog,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Non-english apps\n",
    "Since the fictional company from this exercise only creates apps directed at english speaking people, the next step of the data cleaning will be to remove apps whose name contains non-english characters. It is possible to do so by using ASCII standards of each character within an app's name. The ASCII of english characters falls between 0 and 127, and can luckily be extracted using a python function. \n",
    "\n",
    "Note that emoji's and some symbols' (€) ASCII fall above 127. As such, we need a criteria to allow apps with limited number of characters with ASCII above 127 to be retained in our \"english\" list. To be able to compare the results obtained here with those of DataQuest tutorial the same criterion (3) is used. However, ideally, more in depth analysis, such as the ratio of non-english to english characters should be used. \n",
    "\n",
    "To test whether characters are english ones, the following function provided by the DataQuest tutorial will be used. \n",
    "\n",
    "    Note: running the following cell is MANDATORY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(string):\n",
    "    non_ascii = 0\n",
    "    \n",
    "    for character in string:\n",
    "        if ord(character) > 127:\n",
    "            non_ascii += 1\n",
    "    \n",
    "    if non_ascii > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second function, which I modified form the DataQuest one will be used to clean up the data. \n",
    "    \n",
    "    Note: the function was modified so that it could be applied to both datasets, somethings that was not done by the function suggested in DataQuest's tutorial. \n",
    "    Running the following to cells is MANDATORY for the rest of the code to function properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_language(data,col_nam):\n",
    "    #col_nam is the indice of the column containing the name of the app\n",
    "    tlist = []\n",
    "    coln = col_nam\n",
    "    for rr in data:\n",
    "        if is_english(rr[coln]):\n",
    "            tlist.append(rr)\n",
    "    return tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now to apply the function to the data:\n",
    "ecfilgoog = clean_data_language(cfilgoog,0)\n",
    "efilapp = clean_data_language(filapp,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Free apps\n",
    "Lastly, for cleaning at least, the non-free apps must be removed. The reason being that the fictional company only creates free apps. To do so, a modified version of code provided by DataQuest will be used.\n",
    "\n",
    "    Running the following to cells is MANDATORY for the rest of the code to function properly. Again, the code was improved so that the same function could be used on both datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_free(data,col_cond):\n",
    "    #col_cond is the column with the price of the app\n",
    "    tlist = []\n",
    "    \n",
    "    for rr in data:\n",
    "        if rr[col_cond] == '0':\n",
    "            tlist.append(rr)\n",
    "        \n",
    "    return tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_goog = clean_data_free(ecfilgoog,7)\n",
    "final_app = clean_data_free(efilapp,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "**Finally done with cleaning the data!**\n",
    "**In this step, the cleaned up data will be analyzed.**\n",
    "\n",
    "Now that the data is clean it is possible to analyze it in order to find which kind of app is most likely to be downloaded. As a quick reminder, the fictional company earns money through adds within the apps, the more downloads, the more money they earn. Thus, the goal of this step will be to identify app types that are the most downloaded. We first need to figure out which columns within the datasets can be used to assess the type/category of an app. By taking a look a the description of the fields above, we find that the following ones could be of use: \n",
    " - Google : Category and Genres which correspond to columns 1 and 9 of dataset\n",
    " - Apple : prime_genres which correspond to column 12\n",
    "\n",
    "\n",
    "### 4.1 Looking at categories \n",
    "To assess whether each of these fields can be of use , we first need to obtain a list of the possible types that each entry contains. The following function, that I wrote, will allow us to do that. \n",
    "\n",
    "    Note: Running the following two cells is MANDATORY for the rest of the code to function properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_calculator(data,col):\n",
    "    #This function will create a frequency table of the different types found within a column of the data.\n",
    "    \n",
    "    tdict = {} #output variable is a dictionary\n",
    "    count = 0\n",
    "    \n",
    "    for rr in data:\n",
    "        if isinstance(rr[col],list):\n",
    "            for ee in rr[col]:\n",
    "                if ee in tdict:\n",
    "                    tdict[ee] += 1\n",
    "                else: \n",
    "                    tdict[ee] = 1\n",
    "                count += 1\n",
    "        else:\n",
    "            ee = rr[col]\n",
    "            if ee in tdict:\n",
    "                tdict[ee] += 1\n",
    "            else: \n",
    "                tdict[ee] = 1\n",
    "            count += 1\n",
    "            \n",
    "    for kk in tdict:\n",
    "        tdict[kk] /= count/100\n",
    "    \n",
    "    return tdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqGoogCat = frequency_calculator(final_goog,1)\n",
    "freqGoogGen = frequency_calculator(final_goog,9)\n",
    "freqAppGen = frequency_calculator(final_app,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the number of categories we find for each as well as the list of these categories.\n",
    "\n",
    "    Note: this is FACULTATIVE and for visualization purposes only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different categories for the\n",
      "Google category:  33    Google genre:  114    App genre:  23 \n",
      "\n",
      "['ART_AND_DESIGN', 'Art & Design', 'Productivity']\n",
      "['AUTO_AND_VEHICLES', 'Art & Design;Creativity', 'Weather']\n",
      "['BEAUTY', 'Auto & Vehicles', 'Shopping']\n",
      "['BOOKS_AND_REFERENCE', 'Beauty', 'Reference']\n",
      "['BUSINESS', 'Books & Reference', 'Finance']\n",
      "['COMICS', 'Business', 'Music']\n",
      "['COMMUNICATION', 'Comics', 'Utilities']\n",
      "['DATING', 'Comics;Creativity', 'Travel']\n",
      "['EDUCATION', 'Communication', 'Social Networking']\n",
      "['ENTERTAINMENT', 'Dating', 'Sports']\n"
     ]
    }
   ],
   "source": [
    "print('Number of different categories for the')\n",
    "print('Google category: ',len(freqGoogCat),'   Google genre: ',len(freqGoogGen), '   App genre: ', len(freqAppGen), '\\n')\n",
    "\n",
    "for ii in range(0,10):\n",
    "    print([list(freqGoogCat.keys())[ii],list(freqGoogGen.keys())[ii],list(freqAppGen.keys())[ii]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is kind of hard to read. One way to make a simple and clear table of the frequencies produced by the previous function is to order them so that the most commmon categories appear on top of the list and the least common ones appear at the bottom. DataQuest kindly provides such a function. I have modified it slightly in the cell below. I also added a second function that can take the output of the previous one and display it. The advantage of the second function is that it is made to display multipe dictionaries side by side. \n",
    "\n",
    "        Note: Running the first cells is MANDATORY for the rest of the code to function properly. The second cell is for visualization purposes only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(dataset, index, visu = False):\n",
    "    #Either prints a dictionary ordered by its values (rather than keys) \n",
    "    # or outputs the dictionary so that it is \n",
    "    table = frequency_calculator(dataset, index)\n",
    "    table_display = []\n",
    "    \n",
    "    ke = list(table.keys())\n",
    "    val = list(table.values())\n",
    "\n",
    "    sortke = [x for _,x in sorted(zip(val,ke), reverse = True)]\n",
    "    sortval =  sorted(val, reverse = True)\n",
    "    table_sorted = dict(zip(sortke, sortval))\n",
    "\n",
    "    if visu:\n",
    "        for entry in table_sorted:\n",
    "            print(\"{} {:20}\".format(round(table_sorted[entry],1),entry))\n",
    "    else:\n",
    "        return table_sorted\n",
    "\n",
    "def display_mult_tables(tb1,tb2,tb3,col_names=['Google_Categories','Apple_Genre','Google_Genre']):\n",
    "    \n",
    "    nlin = max([len(tb1),len(tb2),len(tb3)])\n",
    "    print(\"{:25} {:25} {}\".format(*col_names))\n",
    "    \n",
    "    for ll in range(0,nlin-1):\n",
    "        try:\n",
    "            ke1 = list(tb1.keys())[ll]\n",
    "            va1 = round(tb1[ke1],1)\n",
    "        except:\n",
    "            ke1 = ''\n",
    "            va1 = ''\n",
    "\n",
    "        try: \n",
    "            ke2 = list(tb2.keys())[ll]\n",
    "            va2 = round(tb2[ke2],1)\n",
    "        except:\n",
    "            ke2 = ''\n",
    "            va2 = ''\n",
    "\n",
    "        try: \n",
    "            ke3 = list(tb3.keys())[ll]\n",
    "            va3 = round(tb3[ke3],1)\n",
    "        except:\n",
    "            ke3 = ''\n",
    "            va3 = ''\n",
    "        \n",
    "        print(\"{} {:20} {:5} {:20} {:5} {:20}\".format(*[va1,ke1,va2,ke2,va3,ke3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google_Categories         Apple_Genre               Google_Genre\n",
      "18.9 FAMILY                58.2 Games                  8.4 Tools               \n",
      "9.7 GAME                   7.9 Entertainment          6.1 Entertainment       \n",
      "8.5 TOOLS                  5.0 Photo & Video          5.3 Education           \n",
      "4.6 BUSINESS               3.7 Education              4.6 Business            \n",
      "3.9 LIFESTYLE              3.3 Social Networking      3.9 Productivity        \n",
      "3.9 PRODUCTIVITY           2.6 Shopping               3.9 Lifestyle           \n",
      "3.7 FINANCE                2.5 Utilities              3.7 Finance             \n",
      "3.5 MEDICAL                2.1 Sports                 3.5 Medical             \n",
      "3.4 SPORTS                 2.0 Music                  3.5 Sports              \n",
      "3.3 PERSONALIZATION        2.0 Health & Fitness       3.3 Personalization     \n",
      "3.2 COMMUNICATION          1.7 Productivity           3.2 Communication       \n",
      "3.1 HEALTH_AND_FITNESS     1.6 Lifestyle              3.1 Action              \n",
      "2.9 PHOTOGRAPHY            1.3 News                   3.1 Health & Fitness    \n",
      "2.8 NEWS_AND_MAGAZINES     1.2 Travel                 2.9 Photography         \n",
      "2.7 SOCIAL                 1.1 Finance                2.8 News & Magazines    \n",
      "2.3 TRAVEL_AND_LOCAL       0.9 Weather                2.7 Social              \n",
      "2.2 SHOPPING               0.8 Food & Drink           2.3 Travel & Local      \n",
      "2.1 BOOKS_AND_REFERENCE    0.6 Reference              2.2 Shopping            \n",
      "1.9 DATING                 0.5 Business               2.1 Books & Reference   \n",
      "1.8 VIDEO_PLAYERS          0.4 Book                   2.0 Simulation          \n",
      "1.4 MAPS_AND_NAVIGATION    0.2 Navigation             1.9 Dating              \n",
      "1.2 FOOD_AND_DRINK         0.2 Medical                1.9 Arcade              \n",
      "1.2 EDUCATION              0.1 Catalogs               1.8 Video Players & Editors\n",
      "1.0 ENTERTAINMENT                                     1.8 Casual              \n",
      "0.9 LIBRARIES_AND_DEMO                                1.4 Maps & Navigation   \n",
      "0.9 AUTO_AND_VEHICLES                                 1.2 Food & Drink        \n",
      "0.8 HOUSE_AND_HOME                                    1.1 Puzzle              \n",
      "0.8 WEATHER                                           1.0 Racing              \n",
      "0.7 EVENTS                                            0.9 Role Playing        \n",
      "0.7 PARENTING                                         0.9 Libraries & Demo    \n",
      "0.6 ART_AND_DESIGN                                    0.9 Auto & Vehicles     \n",
      "0.6 COMICS                                            0.9 Strategy            \n",
      "0.6 BEAUTY                                            0.8 House & Home        \n",
      "                                                   0.8 Weather             \n",
      "                                                   0.7 Events              \n",
      "                                                   0.7 Adventure           \n",
      "                                                   0.6 Comics              \n",
      "                                                   0.6 Beauty              \n",
      "                                                   0.6 Art & Design        \n",
      "                                                   0.5 Parenting           \n",
      "                                                   0.5 Card                \n",
      "                                                   0.4 Casino              \n",
      "                                                   0.4 Trivia              \n",
      "                                                   0.4 Educational;Education\n",
      "                                                   0.4 Board               \n",
      "                                                   0.4 Educational         \n",
      "                                                   0.3 Education;Education \n",
      "                                                   0.3 Word                \n",
      "                                                   0.2 Casual;Pretend Play \n",
      "                                                   0.2 Music               \n",
      "                                                   0.2 Racing;Action & Adventure\n",
      "                                                   0.2 Puzzle;Brain Games  \n",
      "                                                   0.2 Entertainment;Music & Video\n",
      "                                                   0.1 Casual;Brain Games  \n",
      "                                                   0.1 Casual;Action & Adventure\n",
      "                                                   0.1 Arcade;Action & Adventure\n",
      "                                                   0.1 Action;Action & Adventure\n",
      "                                                   0.1 Educational;Pretend Play\n",
      "                                                   0.1 Simulation;Action & Adventure\n",
      "                                                   0.1 Parenting;Education \n",
      "                                                   0.1 Entertainment;Brain Games\n",
      "                                                   0.1 Board;Brain Games   \n",
      "                                                   0.1 Parenting;Music & Video\n",
      "                                                   0.1 Educational;Brain Games\n",
      "                                                   0.1 Casual;Creativity   \n",
      "                                                   0.1 Art & Design;Creativity\n",
      "                                                   0.1 Education;Pretend Play\n",
      "                                                   0.0 Role Playing;Pretend Play\n",
      "                                                   0.0 Education;Creativity\n",
      "                                                   0.0 Role Playing;Action & Adventure\n",
      "                                                   0.0 Puzzle;Action & Adventure\n",
      "                                                   0.0 Entertainment;Creativity\n",
      "                                                   0.0 Entertainment;Action & Adventure\n",
      "                                                   0.0 Educational;Creativity\n",
      "                                                   0.0 Educational;Action & Adventure\n",
      "                                                   0.0 Education;Music & Video\n",
      "                                                   0.0 Education;Brain Games\n",
      "                                                   0.0 Education;Action & Adventure\n",
      "                                                   0.0 Adventure;Action & Adventure\n",
      "                                                   0.0 Video Players & Editors;Music & Video\n",
      "                                                   0.0 Sports;Action & Adventure\n",
      "                                                   0.0 Simulation;Pretend Play\n",
      "                                                   0.0 Puzzle;Creativity   \n",
      "                                                   0.0 Music;Music & Video \n",
      "                                                   0.0 Entertainment;Pretend Play\n",
      "                                                   0.0 Casual;Education    \n",
      "                                                   0.0 Board;Action & Adventure\n",
      "                                                   0.0 Video Players & Editors;Creativity\n",
      "                                                   0.0 Trivia;Education    \n",
      "                                                   0.0 Travel & Local;Action & Adventure\n",
      "                                                   0.0 Tools;Education     \n",
      "                                                   0.0 Strategy;Education  \n",
      "                                                   0.0 Strategy;Creativity \n",
      "                                                   0.0 Strategy;Action & Adventure\n",
      "                                                   0.0 Simulation;Education\n",
      "                                                   0.0 Role Playing;Brain Games\n",
      "                                                   0.0 Racing;Pretend Play \n",
      "                                                   0.0 Puzzle;Education    \n",
      "                                                   0.0 Parenting;Brain Games\n",
      "                                                   0.0 Music & Audio;Music & Video\n",
      "                                                   0.0 Lifestyle;Pretend Play\n",
      "                                                   0.0 Lifestyle;Education \n",
      "                                                   0.0 Health & Fitness;Education\n",
      "                                                   0.0 Health & Fitness;Action & Adventure\n",
      "                                                   0.0 Entertainment;Education\n",
      "                                                   0.0 Communication;Creativity\n",
      "                                                   0.0 Comics;Creativity   \n",
      "                                                   0.0 Casual;Music & Video\n",
      "                                                   0.0 Card;Action & Adventure\n",
      "                                                   0.0 Books & Reference;Education\n",
      "                                                   0.0 Art & Design;Pretend Play\n",
      "                                                   0.0 Art & Design;Action & Adventure\n",
      "                                                   0.0 Arcade;Pretend Play \n"
     ]
    }
   ],
   "source": [
    "sortGoogCat = display_table(final_goog,1)\n",
    "sortGoogGen = display_table(final_goog,9)\n",
    "sortAppGen = display_table(final_app,12)\n",
    "\n",
    "display_mult_tables(sortGoogCat,sortAppGen,sortGoogGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a much clearer idea of what type of free apps can be found in the Apple Store as well as Google play. \n",
    "\n",
    "### 4.2 Assessing number of apps downloaded by category\n",
    "Although we now know the different categories used to describe apps, we still haven't reached our goal of finding what kind of free apps are most downloaded. That is, even though there might be lots of games on apple store, it does not mean that they are more of them downloaded than for utilities. For instance, there might be a single utility app downloaded by everyone while each game is only downloaded by a few people. \n",
    "\n",
    "Thus, the next step of the analysis is to create a frequency table of downloaded apps by category. Unfortunately, the apple store dataset does not contain this informaiton. It does contain information about the number of ratings of the app which we will take as a proxy for number of downloads (as suggested by the DataQuest tutorial). This is not ideal, but better than nothing.\n",
    "\n",
    "Looking at the legend for each of the dataset (see above), it becomes quite clear which fields to use:\n",
    "\n",
    " - Google: installs, column 5\n",
    " - App: rating_count_tot, column 6\n",
    " \n",
    " \n",
    "     Note: Running the following two cells is MANDATORY for the rest of the code to function properly. The third one is for visualization purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def App_usage(data,col4freq,freqTab,freqTab2data):\n",
    "    #This function takes a dataset and a dictionary of the categories to be explored. \n",
    "    #Two columns must be specified, the one to be searched in the data and the one that \n",
    "    #the frequency table was used from\n",
    "    \n",
    "    table = {}\n",
    "    \n",
    "    for cc in freqTab:\n",
    "        table[cc] = 0\n",
    "        count = 0\n",
    "        \n",
    "        for rr in data:\n",
    "            if isinstance(rr[freqTab2data],list):\n",
    "                for ee in rr[freqTab2data]:\n",
    "                    if ee == cc:\n",
    "                        num = rr[col4freq]\n",
    "                        if num[-1:]== '+':\n",
    "                            num = num.replace('+','')\n",
    "                            num = num.replace(',','')\n",
    "                            table[cc] += int(num)\n",
    "                            count += 1\n",
    "                    \n",
    "                        else:\n",
    "                            table[cc] += int(num)\n",
    "                            count += 1\n",
    "                    \n",
    "            elif rr[freqTab2data] == cc:\n",
    "                num = rr[col4freq]\n",
    "                if num[-1:]== '+':\n",
    "                    num = num.replace('+','')\n",
    "                    num = num.replace(',','')\n",
    "                    table[cc] += int(num)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    table[cc] += int(num)\n",
    "                    count += 1\n",
    "                \n",
    "        table[cc] /= count\n",
    "\n",
    "    # sort the table\n",
    "    ke = list(table.keys())\n",
    "    val = list(table.values())\n",
    "\n",
    "    sortke = [x for _,x in sorted(zip(val,ke), reverse = True)]\n",
    "    sortval =  sorted(val, reverse = True)\n",
    "    \n",
    "    return  dict(zip(sortke, sortval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgUsageGoog = App_usage(final_goog,5,sortGoogCat,1)\n",
    "avgUsageApp = App_usage(final_app,6,sortAppGen,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google_Categories         Apple_Genre               Google_Genre\n",
      "38456119.2 COMMUNICATION        86090.3 Navigation                                     \n",
      "24727872.5 VIDEO_PLAYERS        74942.1 Reference                                      \n",
      "23253652.1 SOCIAL               71548.3 Social Networking                              \n",
      "17840110.4 PHOTOGRAPHY          57326.5 Music                                          \n",
      "16787331.3 PRODUCTIVITY         52279.9 Weather                                        \n",
      "15588015.6 GAME                 39758.5 Book                                           \n",
      "13984077.7 TRAVEL_AND_LOCAL     33333.9 Food & Drink                                   \n",
      "11640705.9 ENTERTAINMENT        31467.9 Finance                                        \n",
      "10801391.3 TOOLS                28441.5 Photo & Video                                  \n",
      "9549178.5 NEWS_AND_MAGAZINES   28243.8 Travel                                         \n",
      "8767811.9 BOOKS_AND_REFERENCE  26919.7 Shopping                                       \n",
      "7036877.3 SHOPPING             23298.0 Health & Fitness                               \n",
      "5201482.6 PERSONALIZATION      23008.9 Sports                                         \n",
      "5074486.2 WEATHER              22788.7 Games                                          \n",
      "4188822.0 HEALTH_AND_FITNESS   21248.0 News                                           \n",
      "4056941.8 MAPS_AND_NAVIGATION  21028.4 Productivity                                   \n",
      "3695641.8 FAMILY               18684.5 Utilities                                      \n",
      "3638640.1 SPORTS               16485.8 Lifestyle                                      \n",
      "1986335.1 ART_AND_DESIGN       14029.8 Entertainment                                  \n",
      "1924897.7 FOOD_AND_DRINK       7491.1 Business                                       \n",
      "1833495.1 EDUCATION            7004.0 Education                                      \n",
      "1712290.1 BUSINESS             4004.0 Catalogs                                       \n",
      "1437816.3 LIFESTYLE            612.0 Medical                                        \n",
      "1387692.5 FINANCE                                                                   \n",
      "1331540.6 HOUSE_AND_HOME                                                            \n",
      "854028.8 DATING                                                                    \n",
      "817657.3 COMICS                                                                    \n",
      "647317.8 AUTO_AND_VEHICLES                                                         \n",
      "638503.7 LIBRARIES_AND_DEMO                                                        \n",
      "542603.6 PARENTING                                                                 \n",
      "513151.9 BEAUTY                                                                    \n",
      "253542.2 EVENTS                                                                    \n"
     ]
    }
   ],
   "source": [
    "display_mult_tables(avgUsageGoog,avgUsageApp,{})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final note\n",
    "The DataQuest tutorial suggests the analyses that were carried above. However, simply having an average number of app downloaded for each category is quite limited as outliers might be dragging the means. For instance, google map and similarly other well known navigation apps are likely to dominate the field of navigation whereas outside of this small clique, others are likely present in smaller number. To assess such hypothesis in an efficient manner we would need to display histograms. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
